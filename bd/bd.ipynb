{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e76bbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136b094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_mortalidade = pd.read_csv('../dados/base_dados/tabua_concatenada.csv')\n",
    "arima_ets = pd.read_csv('../dados/arima-ets/tabuas_combinad.csv')\n",
    "lc = pd.read_csv('../dados/lc-lm/tabua_lc.csv')\n",
    "lm = pd.read_csv('../dados/lc-lm/tabua_lm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2340a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_ets['sexo'] = arima_ets['sexo'].map({'Homens': 'Masculino', 'Mulheres': 'Feminino', 'Ambos': 'Ambos'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec43fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padrão = ['ano', 'faixa_etaria', 'nMx', 'nqx', 'nAx', 'lx', 'ndx', 'nLx', 'Tx', 'ex', 'local', 'sexo']\n",
    "# renomenado as colunas para o padrao\n",
    "arima_ets = arima_ets.rename(columns={\n",
    "    'ano': 'ano',\n",
    "    'faixa_etaria': 'faixa_etaria',\n",
    "    'nMx': 'nMx',\n",
    "    'nqx': 'nqx',\n",
    "    'ax': 'nAx',\n",
    "    'lx': 'lx',\n",
    "    'dx': 'ndx',\n",
    "    'Lx': 'nLx',\n",
    "    'Tx': 'Tx',\n",
    "    'ex': 'ex',\n",
    "    'local': 'local',\n",
    "    'sexo': 'sexo'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57536f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ano', 'faixa_etaria', 'nMx', 'local', 'sexo', 'nAx', 'n', 'nqx', 'lx',\n",
      "       'ndx', 'nLx', 'Tx', 'ex'],\n",
      "      dtype='object') Index(['ano', 'faixa_etaria', 'nMx', 'nqx', 'nAx', 'lx', 'ndx', 'nLx', 'Tx',\n",
      "       'ex', 'local', 'sexo'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(arima_ets.columns,\n",
    "dados_mortalidade.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba66324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f2dff330540>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 2. CONEXÃO COM O BANCO (Cria o arquivo .db automaticamente) ---\n",
    "conn = sqlite3.connect('banco_atuarial.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# --- 3. CRIAR A ESTRUTURA (SQL) ---\n",
    "# Habilitar chaves estrangeiras no SQLite\n",
    "cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "# ano\tfaixa_etaria\tnMx\tnqx\tnAx\tlx\tndx\tnLx\tTx\tex\tlocal\tsexo\n",
    "# Criar tabelas\n",
    "script_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dim_locais (id_local INTEGER PRIMARY KEY AUTOINCREMENT, nome_local TEXT UNIQUE);\n",
    "CREATE TABLE IF NOT EXISTS dim_faixas (id_faixa INTEGER PRIMARY KEY AUTOINCREMENT, descricao TEXT UNIQUE);\n",
    "CREATE TABLE IF NOT EXISTS dim_sexo (id_sexo INTEGER PRIMARY KEY AUTOINCREMENT, descricao TEXT UNIQUE);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS tabua_mortalidade (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    id_local INTEGER,\n",
    "    id_faixa INTEGER,\n",
    "    id_sexo INTEGER,\n",
    "    ano INTEGER,\n",
    "    nMx REAL,\n",
    "    nqx REAL,\n",
    "    nAx REAL,\n",
    "    lx REAL,\n",
    "    ndx REAL,\n",
    "    nLx REAL,\n",
    "    Tx REAL,\n",
    "    ex REAL,\n",
    "    FOREIGN KEY(id_local) REFERENCES dim_locais(id_local),\n",
    "    FOREIGN KEY(id_faixa) REFERENCES dim_faixas(id_faixa),\n",
    "    FOREIGN KEY(id_sexo) REFERENCES dim_sexo(id_sexo)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS tabua_arima_ets (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    id_local INTEGER,\n",
    "    id_faixa INTEGER,\n",
    "    id_sexo INTEGER,\n",
    "    ano INTEGER,\n",
    "    nMx REAL,\n",
    "    nqx REAL,\n",
    "    nAx REAL,\n",
    "    lx REAL,\n",
    "    ndx REAL,\n",
    "    nLx REAL,\n",
    "    Tx REAL,\n",
    "    ex REAL,\n",
    "    FOREIGN KEY(id_local) REFERENCES dim_locais(id_local),\n",
    "    FOREIGN KEY(id_faixa) REFERENCES dim_faixas(id_faixa),\n",
    "    FOREIGN KEY(id_sexo) REFERENCES dim_sexo(id_sexo)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.executescript(script_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9603dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. POPULAR DIMENSÕES (A Mágica do Python + SQL) ---\n",
    "\n",
    "def popular_dimensao(df, nome_tabela, coluna_df, coluna_banco):\n",
    "    # Pega valores únicos do DataFrame\n",
    "    unicos = df[coluna_df].unique()\n",
    "    \n",
    "    # Insere no banco (IGNORANDO duplicatas se já existirem)\n",
    "    for item in unicos:\n",
    "        cursor.execute(f\"INSERT OR IGNORE INTO {nome_tabela} ({coluna_banco}) VALUES (?)\", (item,))\n",
    "    conn.commit()\n",
    "    \n",
    "    # Lê de volta do banco para pegar os IDs gerados\n",
    "    return pd.read_sql(f\"SELECT * FROM {nome_tabela}\", conn)\n",
    "\n",
    "# Executa para as 3 dimensões\n",
    "df_dim_locais = popular_dimensao(dados_mortalidade, 'dim_locais', 'local', 'nome_local')\n",
    "df_dim_faixas = popular_dimensao(dados_mortalidade, 'dim_faixas', 'faixa_etaria', 'descricao')\n",
    "df_dim_sexo   = popular_dimensao(dados_mortalidade, 'dim_sexo', 'sexo', 'descricao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29592383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_sexo  descricao\n",
      "0        1      Ambos\n",
      "1        2   Feminino\n",
      "2        3  Masculino\n"
     ]
    }
   ],
   "source": [
    "print(df_dim_sexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b6e103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. PREPARAR A TABELA FATO ---\n",
    "# Agora substituímos os textos pelos IDs recém criados\n",
    "df_fato = dados_mortalidade.copy()\n",
    "\n",
    "# Faz o \"Merge\" (Join) para trazer os IDs para o DataFrame principal\n",
    "df_fato = df_fato.merge(df_dim_locais, left_on='local', right_on='nome_local')\n",
    "df_fato = df_fato.merge(df_dim_faixas, left_on='faixa_etaria', right_on='descricao')\n",
    "df_fato = df_fato.merge(df_dim_sexo, left_on='sexo', right_on='descricao')\n",
    "\n",
    "# Seleciona apenas as colunas finais\n",
    "cols_finais = ['id_local', 'id_faixa', 'id_sexo', 'ano', 'nMx', 'nqx', 'nAx', 'lx', 'ndx', 'nLx', 'Tx', 'ex']\n",
    "df_fato_final = df_fato[cols_finais]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3388cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sucesso! Dados salvos no SQLite ---\n",
      "Veja como ficou a tabela fato (só números):\n",
      "          id  id_local  id_faixa  id_sexo   ano       nMx       nqx       nAx  \\\n",
      "0          1         1         1        1  2000  0.028834  0.028127  0.128739   \n",
      "1          2         1         2        1  2000   0.00115  0.004588  1.524332   \n",
      "2          3         1         3        1  2000  0.000376  0.001881  2.286499   \n",
      "3          4         1         4        1  2000  0.000436  0.002178  2.751711   \n",
      "4          5         1         5        1  2000  0.001266  0.006311  2.800300   \n",
      "...      ...       ...       ...      ...   ...       ...       ...       ...   \n",
      "47515  47516        33        16        3  2023  0.025749  0.121349  2.632319   \n",
      "47516  47517        33        17        3  2023  0.042221  0.191909  2.630570   \n",
      "47517  47518        33        18        3  2023  0.073506  0.311504  2.553266   \n",
      "47518  47519        33        19        3  2023  0.113711  0.444458  2.544557   \n",
      "47519  47520        33        20        3  2023  0.283821  1.000000  3.523346   \n",
      "\n",
      "                  lx           ndx            nLx            Tx         ex  \n",
      "0      100000.000000   2812.697459   97549.406182  7.110219e+06  71.102185  \n",
      "1       97187.302541    445.882150  387645.354108  7.012669e+06  72.156227  \n",
      "2       96741.420390    181.924588  483213.449343  6.625024e+06  68.481771  \n",
      "3       96559.495802    210.311936  482324.637048  6.141810e+06  63.606487  \n",
      "4       96349.183866    608.103078  480408.275043  5.659486e+06  58.739321  \n",
      "...              ...           ...            ...           ...        ...  \n",
      "47515   74089.454949   8990.670140  349160.238874  1.080448e+06  14.583018  \n",
      "47516   65098.784808  12493.023240  295892.576723  7.312876e+05  11.233506  \n",
      "47517   52605.761568  16386.919793  222934.373169  4.353950e+05   8.276565  \n",
      "47518   36218.841775  16097.755672  141567.079626  2.124606e+05   5.866025  \n",
      "47519   20121.086102  20121.086102   70893.554341  7.089355e+04   3.523346  \n",
      "\n",
      "[47520 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- 6. SALVAR NO BANCO ---\n",
    "df_fato_final.to_sql('fato_projecoes', conn, if_exists='append', index=False)\n",
    "\n",
    "print(\"\\n--- Sucesso! Dados salvos no SQLite ---\")\n",
    "print(\"Veja como ficou a tabela fato (só números):\")\n",
    "print(pd.read_sql(\"SELECT * FROM fato_projecoes\", conn))\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3245587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. CONEXÃO COM O BANCO (Cria o arquivo .db automaticamente) ---\n",
    "conn = sqlite3.connect('banco_atuarial.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# --- 3. CRIAR A ESTRUTURA (SQL) ---\n",
    "# Habilitar chaves estrangeiras no SQLite\n",
    "cursor.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "\n",
    "# Criar tabelas\n",
    "script_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dim_locais (id_local INTEGER PRIMARY KEY AUTOINCREMENT, nome_local TEXT UNIQUE);\n",
    "CREATE TABLE IF NOT EXISTS dim_faixas (id_faixa INTEGER PRIMARY KEY AUTOINCREMENT, descricao TEXT UNIQUE);\n",
    "CREATE TABLE IF NOT EXISTS dim_sexo (id_sexo INTEGER PRIMARY KEY AUTOINCREMENT, descricao TEXT UNIQUE);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS fato_projecoes (\n",
    "    id_projecao INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    id_local INTEGER,\n",
    "    id_faixa INTEGER,\n",
    "    id_sexo INTEGER,\n",
    "    ano INTEGER,\n",
    "    previsto REAL,\n",
    "    lmt_inf REAL,\n",
    "    lmt_max REAL,\n",
    "    FOREIGN KEY(id_local) REFERENCES dim_locais(id_local),\n",
    "    FOREIGN KEY(id_faixa) REFERENCES dim_faixas(id_faixa),\n",
    "    FOREIGN KEY(id_sexo) REFERENCES dim_sexo(id_sexo)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.executescript(script_sql)\n",
    "\n",
    "# --- 4. POPULAR DIMENSÕES (A Mágica do Python + SQL) ---\n",
    "\n",
    "def popular_dimensao(nome_tabela, coluna_df, coluna_banco):\n",
    "    # Pega valores únicos do DataFrame\n",
    "    unicos = df_origem[coluna_df].unique()\n",
    "    \n",
    "    # Insere no banco (IGNORANDO duplicatas se já existirem)\n",
    "    for item in unicos:\n",
    "        cursor.execute(f\"INSERT OR IGNORE INTO {nome_tabela} ({coluna_banco}) VALUES (?)\", (item,))\n",
    "    conn.commit()\n",
    "    \n",
    "    # Lê de volta do banco para pegar os IDs gerados\n",
    "    return pd.read_sql(f\"SELECT * FROM {nome_tabela}\", conn)\n",
    "\n",
    "# Executa para as 3 dimensões\n",
    "df_dim_locais = popular_dimensao('dim_locais', 'Local', 'nome_local')\n",
    "df_dim_faixas = popular_dimensao('dim_faixas', 'faixa_etaria', 'descricao')\n",
    "df_dim_sexo   = popular_dimensao('dim_sexo', 'sexo', 'descricao')\n",
    "\n",
    "# --- 5. PREPARAR A TABELA FATO ---\n",
    "# Agora substituímos os textos pelos IDs recém criados\n",
    "df_fato = df_origem.copy()\n",
    "\n",
    "# Faz o \"Merge\" (Join) para trazer os IDs para o DataFrame principal\n",
    "df_fato = df_fato.merge(df_dim_locais, left_on='Local', right_on='nome_local')\n",
    "df_fato = df_fato.merge(df_dim_faixas, left_on='faixa_etaria', right_on='descricao')\n",
    "df_fato = df_fato.merge(df_dim_sexo, left_on='sexo', right_on='descricao')\n",
    "\n",
    "# Seleciona apenas as colunas finais\n",
    "cols_finais = ['id_local', 'id_faixa', 'id_sexo', 'ano', 'previsto', 'lmt_inf', 'lmt_max']\n",
    "df_fato_final = df_fato[cols_finais]\n",
    "\n",
    "# --- 6. SALVAR NO BANCO ---\n",
    "df_fato_final.to_sql('fato_projecoes', conn, if_exists='append', index=False)\n",
    "\n",
    "print(\"\\n--- Sucesso! Dados salvos no SQLite ---\")\n",
    "print(\"Veja como ficou a tabela fato (só números):\")\n",
    "print(pd.read_sql(\"SELECT * FROM fato_projecoes\", conn))\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
